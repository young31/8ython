{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_dir = 'C:/Users/student/Desktop/dataset'\n",
    "base_dir = base_dir='C:/Users/student/Desktop/dataset/set'\n",
    "\n",
    "train_dir='C:/Users/student/Desktop/dataset/set/train'\n",
    "val_dir='C:/Users/student/Desktop/dataset/set/val'\n",
    "test_dir='C:/Users/student/Desktop/dataset/set/test'\n",
    "\n",
    "train_cats_dir=f'C:/Users/student/Desktop/dataset/set/train/cats'\n",
    "train_dogs_dir='C:/Users/student/Desktop/dataset/set/train/dogs'\n",
    "val_cats_dir='C:/Users/student/Desktop/dataset/set/val/cats'\n",
    "val_dogs_dir='C:/Users/student/Desktop/dataset/set/val/dogs'\n",
    "test_cats_dir='C:/Users/student/Desktop/dataset/set/test'\n",
    "test_dogs_dir='C:/Users/student/Desktop/dataset/set/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_gen = ImageDataGenerator(rescale = 1/255,\n",
    "                             zoom_range= 0.2)\n",
    "data_gen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "train_gen = train_data_gen.flow_from_directory(train_dir,\n",
    "                                        target_size=(150,150),\n",
    "                                        batch_size=20,\n",
    "                                        class_mode='categorical')\n",
    "val_gen = data_gen.flow_from_directory(val_dir,\n",
    "                                        target_size=(150,150),\n",
    "                                        batch_size=20,\n",
    "                                        class_mode='categorical')\n",
    "test_gen = data_gen.flow_from_directory(test_dir,\n",
    "                                        target_size=(150,150),\n",
    "                                        batch_size=20,\n",
    "                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0715 13:31:21.579968 12884 deprecation_wrapper.py:119] From c:\\users\\student\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0715 13:31:21.589895 12884 deprecation_wrapper.py:119] From c:\\users\\student\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0715 13:31:21.591940 12884 deprecation_wrapper.py:119] From c:\\users\\student\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0715 13:31:21.607848 12884 deprecation_wrapper.py:119] From c:\\users\\student\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0715 13:31:21.861233 12884 deprecation_wrapper.py:119] From c:\\users\\student\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0715 13:31:21.861233 12884 deprecation_wrapper.py:119] From c:\\users\\student\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_vgg16 =VGG16(weights='imagenet', include_top=False,input_shape=(150,150,3))\n",
    "conv_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in conv_vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 16,812,610\n",
      "Trainable params: 2,097,922\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers, optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(conv_vgg16)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "             loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 99s 991ms/step - loss: 0.6031 - acc: 0.6850 - val_loss: 0.4709 - val_acc: 0.8200\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 98s 981ms/step - loss: 0.4509 - acc: 0.8160 - val_loss: 0.3937 - val_acc: 0.8430\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 98s 978ms/step - loss: 0.3821 - acc: 0.8490 - val_loss: 0.3315 - val_acc: 0.8760\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 97s 973ms/step - loss: 0.3407 - acc: 0.8665 - val_loss: 0.3135 - val_acc: 0.8830\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 98s 980ms/step - loss: 0.3124 - acc: 0.8745 - val_loss: 0.3109 - val_acc: 0.8820\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 97s 968ms/step - loss: 0.2917 - acc: 0.8835 - val_loss: 0.2928 - val_acc: 0.8850\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 97s 969ms/step - loss: 0.2741 - acc: 0.8970 - val_loss: 0.2582 - val_acc: 0.9090\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 98s 977ms/step - loss: 0.2636 - acc: 0.9015 - val_loss: 0.2642 - val_acc: 0.8960\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 97s 968ms/step - loss: 0.2628 - acc: 0.8980 - val_loss: 0.2616 - val_acc: 0.9040\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 97s 971ms/step - loss: 0.2373 - acc: 0.9090 - val_loss: 0.2658 - val_acc: 0.8930\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch = 100,\n",
    "                              epochs = 10,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_pool\n",
      "11 block4_conv1\n",
      "12 block4_conv2\n",
      "13 block4_conv3\n",
      "14 block4_pool\n",
      "15 block5_conv1\n",
      "16 block5_conv2\n",
      "17 block5_conv3\n",
      "18 block5_pool\n"
     ]
    }
   ],
   "source": [
    "# fine tuning\n",
    "\n",
    "for i, layer in enumerate(conv_vgg16.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in conv_vgg16.layers[:15]:\n",
    "    layer.trainable = False\n",
    "for layer in conv_vgg16.layers[15:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-6),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.2281 - acc: 0.9115 - val_loss: 0.2410 - val_acc: 0.8990\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 118s 1s/step - loss: 0.2091 - acc: 0.9265 - val_loss: 0.2246 - val_acc: 0.9170\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.1943 - acc: 0.9295 - val_loss: 0.2314 - val_acc: 0.9040\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.1869 - acc: 0.9365 - val_loss: 0.2220 - val_acc: 0.9150\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 118s 1s/step - loss: 0.1778 - acc: 0.9305 - val_loss: 0.2457 - val_acc: 0.8980\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 123s 1s/step - loss: 0.1704 - acc: 0.9375 - val_loss: 0.2122 - val_acc: 0.9040\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.1614 - acc: 0.9380 - val_loss: 0.2102 - val_acc: 0.9140\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.1616 - acc: 0.9470 - val_loss: 0.2148 - val_acc: 0.9050\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.1550 - acc: 0.9450 - val_loss: 0.2173 - val_acc: 0.9160\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.1422 - acc: 0.9480 - val_loss: 0.2063 - val_acc: 0.9030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch = 100,\n",
    "                              epochs = 10,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9598382  0.04016181]]\n",
      "0.04089546203613281\n"
     ]
    }
   ],
   "source": [
    "from keras import preprocessing\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "img = preprocessing.image.load_img('C:/Users/student/Desktop/oyster.jpg', \n",
    "                               target_size = (150,150))\n",
    "img = preprocessing.image.img_to_array(img)\n",
    "img = np.reshape(img, (1,150,150,3))/255\n",
    "print(model.predict(img))\n",
    "\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
